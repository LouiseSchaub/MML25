{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbdeedd-b922-42c6-97c3-14c6d3fb61da",
   "metadata": {},
   "source": [
    "# Mathematical Machine Learning – Tutorial 3  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210e46c-80c0-4a0c-9f0c-90d118285743",
   "metadata": {},
   "source": [
    "## Exercise 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aaa8a38-2da9-4a7e-8157-1585d33407d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd3c7e-6e8d-4091-82ff-500f56fb71e1",
   "metadata": {},
   "source": [
    "### a) Inspecting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2fdee2-dcd4-46a2-b014-12cc1d096c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name     role         type demographic  \\\n",
      "0          fixed_acidity  Feature   Continuous        None   \n",
      "1       volatile_acidity  Feature   Continuous        None   \n",
      "2            citric_acid  Feature   Continuous        None   \n",
      "3         residual_sugar  Feature   Continuous        None   \n",
      "4              chlorides  Feature   Continuous        None   \n",
      "5    free_sulfur_dioxide  Feature   Continuous        None   \n",
      "6   total_sulfur_dioxide  Feature   Continuous        None   \n",
      "7                density  Feature   Continuous        None   \n",
      "8                     pH  Feature   Continuous        None   \n",
      "9              sulphates  Feature   Continuous        None   \n",
      "10               alcohol  Feature   Continuous        None   \n",
      "11               quality   Target      Integer        None   \n",
      "12                 color    Other  Categorical        None   \n",
      "\n",
      "               description units missing_values  \n",
      "0                     None  None             no  \n",
      "1                     None  None             no  \n",
      "2                     None  None             no  \n",
      "3                     None  None             no  \n",
      "4                     None  None             no  \n",
      "5                     None  None             no  \n",
      "6                     None  None             no  \n",
      "7                     None  None             no  \n",
      "8                     None  None             no  \n",
      "9                     None  None             no  \n",
      "10                    None  None             no  \n",
      "11  score between 0 and 10  None             no  \n",
      "12            red or white  None             no  \n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine_quality.data.features \n",
    "y = wine_quality.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(wine_quality.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(wine_quality.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88fd8e0-99c1-4749-b0c1-e59d557aafaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name     role     type demographic description units missing_values\n",
      "0   Rad Flow  Feature  Integer        None        None  None             no\n",
      "1  Fpv Close  Feature  Integer        None        None  None             no\n",
      "2   Fpv Open  Feature  Integer        None        None  None             no\n",
      "3       High  Feature  Integer        None        None  None             no\n",
      "4     Bypass  Feature  Integer        None        None  None             no\n",
      "5  Bpv Close  Feature  Integer        None        None  None             no\n",
      "6   Bpv Open  Feature  Integer        None        None  None             no\n",
      "7      class   Target  Integer        None        None  None             no\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "statlog_shuttle = fetch_ucirepo(id=148) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_shuttle.data.features \n",
    "y = statlog_shuttle.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(statlog_shuttle.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(statlog_shuttle.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a822c-3392-4b4f-a554-e6f399a963ac",
   "metadata": {},
   "source": [
    "## Exercise 2 – Modeling Inputs / Outputs\n",
    "\n",
    "We consider two UCI datasets:\n",
    "\n",
    "1. Wine Quality dataset (red / white Vinho Verde wines).  \n",
    "2. Statlog (Shuttle) dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### (a) Description of the datasets and variables\n",
    "\n",
    "#### Wine Quality\n",
    "\n",
    "- Two related datasets: red (1599 samples) and white (4898 samples) wines.\n",
    "- Each row corresponds to one wine sample.\n",
    "- **Inputs (11 continuous features):**\n",
    "  1. fixed acidity  \n",
    "  2. volatile acidity  \n",
    "  3. citric acid  \n",
    "  4. residual sugar  \n",
    "  5. chlorides  \n",
    "  6. free sulfur dioxide  \n",
    "  7. total sulfur dioxide  \n",
    "  8. density  \n",
    "  9. pH  \n",
    "  10. sulphates  \n",
    "  11. alcohol\n",
    "- **Output:** `quality` – integer sensory score from 0–10 (in practice usually 3–8).\n",
    "\n",
    "Typical ranges (roughly):\n",
    "- fixed acidity: about 4–16 g/dm³,  \n",
    "- alcohol: about 8–15 % vol,  \n",
    "- quality: small integer.\n",
    "\n",
    "#### Statlog (Shuttle)\n",
    "\n",
    "- Around 58,000 instances; 9 input attributes and 1 output label.\n",
    "- Inputs: 9 numerical attributes (time and sensor measurements of the space shuttle’s control system).\n",
    "- Output: 7-class categorical label describing the shuttle state, e.g.:\n",
    "  - Rad.Flow\n",
    "  - Fpv.Close\n",
    "  - Fpv.Open\n",
    "  - High\n",
    "  - Bypass\n",
    "  - Bpv.Close\n",
    "  - Bpv.Open\n",
    "- Strong class imbalance (majority of samples in class 1).\n",
    "\n",
    "---\n",
    "\n",
    "### (b) Modeling via random variables / vectors\n",
    "\n",
    "#### Wine Quality\n",
    "\n",
    "Let\n",
    "\\[\n",
    "X =\n",
    "\\begin{pmatrix}\n",
    "X_1 \\\\ \\vdots \\\\ X_{11}\n",
    "\\end{pmatrix}\n",
    "\\in \\mathbb{R}^{11}\n",
    "\\]\n",
    "be the random input vector of physicochemical features:\n",
    "\n",
    "- \\(X_1\\): fixed acidity,  \n",
    "- \\(\\dots\\),  \n",
    "- \\(X_{11}\\): alcohol content.\n",
    "\n",
    "Let \\(Y \\in \\{0,1,\\dots,10\\}\\) be the discrete output random variable representing the quality score.\n",
    "\n",
    "Each sample from the dataset is an i.i.d. realization \\((x^{(k)}, y^{(k)})\\) from the joint distribution \\(P_{X,Y}\\).\n",
    "\n",
    "#### Statlog (Shuttle)\n",
    "\n",
    "Let\n",
    "\\[\n",
    "Z \\in \\mathbb{R}^9\n",
    "\\]\n",
    "be the 9-dimensional input vector (time + 8 sensor measurements), and let\n",
    "\\[\n",
    "C \\in \\{1,2,\\dots,7\\}\n",
    "\\]\n",
    "be the class label representing the shuttle state.\n",
    "\n",
    "Again, each dataset row is an i.i.d. sample \\((z^{(k)}, c^{(k)})\\) from \\(P_{Z,C}\\).\n",
    "\n",
    "---\n",
    "\n",
    "### (c) Type of machine learning tasks\n",
    "\n",
    "#### Wine Quality\n",
    "\n",
    "- The dataset is mainly used for **supervised learning**.\n",
    "- Two standard views:\n",
    "  1. **Regression:** predict the numerical quality score \\(Y\\) from inputs \\(X\\).\n",
    "  2. **Classification:** treat quality as a discrete class (possibly ordinal), e.g. “low”, “medium”, “high”.\n",
    "\n",
    "Unsupervised tasks such as clustering wines are also possible but not the main focus.\n",
    "\n",
    "#### Statlog (Shuttle)\n",
    "\n",
    "- This is a **supervised multi-class classification** problem:\n",
    "  - Input: 9 real-valued attributes.\n",
    "  - Output: class \\(C \\in \\{1,\\dots,7\\}\\).\n",
    "- Because of the class imbalance, metrics like macro F1-score can be more informative than plain accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### (d) Specific ML problem formulations\n",
    "\n",
    "#### Wine Quality – Regression problem\n",
    "\n",
    "**Problem statement.**  \n",
    "Given the 11-dimensional physicochemical measurements \\(X\\) of a wine, predict its quality score \\(Y\\).\n",
    "\n",
    "We learn a function\n",
    "\\[\n",
    "f:\\mathbb{R}^{11} \\to \\mathbb{R}\n",
    "\\]\n",
    "that approximates\n",
    "\\[\n",
    "f^\\*(x) = \\mathbb{E}[Y \\mid X=x]\n",
    "\\]\n",
    "using a regression model (e.g. linear regression or random forest).  \n",
    "Optionally, we round the predicted value to the nearest integer to obtain a discrete quality label.\n",
    "\n",
    "Alternative classification problem:\n",
    "\n",
    "- Define a binary label:\n",
    "  \\[\n",
    "  Y' =\n",
    "    \\begin{cases}\n",
    "      1, & \\text{quality} \\ge 7 \\quad (\\text{“good”})\\\\\n",
    "      0, & \\text{quality} \\le 6 \\quad (\\text{“not good”})\n",
    "    \\end{cases}\n",
    "  \\]\n",
    "- Learn a classifier \\(g: \\mathbb{R}^{11} \\to \\{0,1\\}\\).\n",
    "\n",
    "#### Statlog (Shuttle) – Multi-class classification\n",
    "\n",
    "**Problem statement.**  \n",
    "Given a 9-dimensional vector of shuttle sensor readings \\(Z\\), predict the shuttle’s operational state \\(C \\in \\{1,\\dots,7\\}\\).\n",
    "\n",
    "We learn a classifier\n",
    "\\[\n",
    "h: \\mathbb{R}^9 \\to \\{1,\\dots,7\\},\n",
    "\\]\n",
    "for example a multi-class logistic regression, decision tree, or neural network, trained to approximate\n",
    "\\[\n",
    "h^\\*(z) = \\arg\\max_{c} \\mathbb{P}(C=c \\mid Z=z).\n",
    "\\]\n",
    "In evaluation, we take class imbalance into account using suitable metrics (per-class recall, macro F1, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f24849-e547-4582-bc19-85f4a1d84d60",
   "metadata": {},
   "source": [
    "## Exercise 3 – Detecting Spam (Spambase)\n",
    "\n",
    "The Spambase dataset uses 57 input features to describe emails and a binary label\n",
    "indicating whether an email is spam (1) or not spam (0).\n",
    "\n",
    "---\n",
    "\n",
    "### (a) Description of the 57 input variables\n",
    "\n",
    "The 57 features can be grouped into three categories:\n",
    "\n",
    "1. **48 word frequency features**, of the form\n",
    "   \\[\n",
    "   \\text{word\\_freq\\_<WORD>} = 100 \\cdot \\frac{\\text{# of occurrences of <WORD>}}{\\text{total # of words in the email}}.\n",
    "   \\]\n",
    "   The words are (in order):\n",
    "\n",
    "   1. `word_freq_make`  \n",
    "   2. `word_freq_address`  \n",
    "   3. `word_freq_all`  \n",
    "   4. `word_freq_3d`  \n",
    "   5. `word_freq_our`  \n",
    "   6. `word_freq_over`  \n",
    "   7. `word_freq_remove`  \n",
    "   8. `word_freq_internet`  \n",
    "   9. `word_freq_order`  \n",
    "   10. `word_freq_mail`  \n",
    "   11. `word_freq_receive`  \n",
    "   12. `word_freq_will`  \n",
    "   13. `word_freq_people`  \n",
    "   14. `word_freq_report`  \n",
    "   15. `word_freq_addresses`  \n",
    "   16. `word_freq_free`  \n",
    "   17. `word_freq_business`  \n",
    "   18. `word_freq_email`  \n",
    "   19. `word_freq_you`  \n",
    "   20. `word_freq_credit`  \n",
    "   21. `word_freq_your`  \n",
    "   22. `word_freq_font`  \n",
    "   23. `word_freq_000`  \n",
    "   24. `word_freq_money`  \n",
    "   25. `word_freq_hp`  \n",
    "   26. `word_freq_hpl`  \n",
    "   27. `word_freq_george`  \n",
    "   28. `word_freq_650`  \n",
    "   29. `word_freq_lab`  \n",
    "   30. `word_freq_labs`  \n",
    "   31. `word_freq_telnet`  \n",
    "   32. `word_freq_857`  \n",
    "   33. `word_freq_data`  \n",
    "   34. `word_freq_415`  \n",
    "   35. `word_freq_85`  \n",
    "   36. `word_freq_technology`  \n",
    "   37. `word_freq_1999`  \n",
    "   38. `word_freq_parts`  \n",
    "   39. `word_freq_pm`  \n",
    "   40. `word_freq_direct`  \n",
    "   41. `word_freq_cs`  \n",
    "   42. `word_freq_meeting`  \n",
    "   43. `word_freq_original`  \n",
    "   44. `word_freq_project`  \n",
    "   45. `word_freq_re`  \n",
    "   46. `word_freq_edu`  \n",
    "   47. `word_freq_table`  \n",
    "   48. `word_freq_conference`  \n",
    "\n",
    "2. **6 character frequency features**, also in percent:\n",
    "   \\[\n",
    "   \\text{char\\_freq\\_<CHAR>} = 100 \\cdot \\frac{\\text{# of <CHAR> characters}}{\\text{total # of characters}}.\n",
    "   \\]\n",
    "\n",
    "   49. `char_freq_semicolon`  (frequency of `;`)  \n",
    "   50. `char_freq_left_paren` (frequency of `(`)  \n",
    "   51. `char_freq_left_bracket` (frequency of `[`)  \n",
    "   52. `char_freq_exclamation` (frequency of `!`)  \n",
    "   53. `char_freq_dollar`     (frequency of `$`)  \n",
    "   54. `char_freq_pound`      (frequency of `#`)  \n",
    "\n",
    "3. **3 capital-letter run-length features**:\n",
    "   - 55. `capital_run_length_average`: average length of uninterrupted sequences of capital letters.  \n",
    "   - 56. `capital_run_length_longest`: length of the longest uninterrupted sequence of uppercase letters.  \n",
    "   - 57. `capital_run_length_total`: total number of uppercase letters (sum of all run lengths).\n",
    "\n",
    "The **class label** is a separate binary variable indicating spam (1) or non-spam (0).\n",
    "\n",
    "---\n",
    "\n",
    "### (b) Alternative feature set for spam detection\n",
    "\n",
    "Beyond the handcrafted Spambase features, modern spam filters often use richer feature sets, e.g.:\n",
    "\n",
    "1. **Character-based features**\n",
    "   - Frequencies of punctuation (`!`, `?`, `*`, etc.).\n",
    "   - Ratios of uppercase to lowercase letters.\n",
    "   - Character n-grams like repeated symbols (“$$”, “!!!”).\n",
    "\n",
    "2. **Word-based features**\n",
    "   - Bag-of-words or TF–IDF representations of tokens.\n",
    "   - Presence of typical spam keywords such as “lottery”, “prize”, “winner”, “investment”, “offer”.\n",
    "   - Word n-grams (bigrams, trigrams) capturing short phrases.\n",
    "\n",
    "3. **HTML / tag-based features**\n",
    "   - Counts of `<a>`, `<img>`, `<script>` tags in HTML emails.\n",
    "   - Presence of obfuscated links or hidden text.\n",
    "   - Whether the email is plain-text vs. HTML.\n",
    "\n",
    "4. **Structural features**\n",
    "   - Email length (characters, words, lines).\n",
    "   - Number of URLs and their average lengths.\n",
    "   - Number of attachments or images.\n",
    "\n",
    "5. **Header-based features**\n",
    "   - Sender domain (freemail vs. corporate).\n",
    "   - Mismatch between `From` and `Reply-To` domains.\n",
    "   - Subject line properties (length, presence of all caps, many exclamation marks, etc.).\n",
    "\n",
    "Such feature sets can be combined with modern classifiers (e.g. gradient boosting, neural networks) and often outperform the simple 57-feature Spambase representation on current email traffic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784ae06-fb77-4cf1-88f6-04321066625a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f99576-4ba1-4a95-89af-42da681ce2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b675c0d-2657-40c4-be3b-d821bf9d596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words and characters as defined by Spambase\n",
    "SPAMBASE_WORDS = [\n",
    "    \"make\", \"address\", \"all\", \"3d\", \"our\", \"over\", \"remove\", \"internet\",\n",
    "    \"order\", \"mail\", \"receive\", \"will\", \"people\", \"report\", \"addresses\",\n",
    "    \"free\", \"business\", \"email\", \"you\", \"credit\", \"your\", \"font\", \"000\",\n",
    "    \"money\", \"hp\", \"hpl\", \"george\", \"650\", \"lab\", \"labs\", \"telnet\", \"857\",\n",
    "    \"data\", \"415\", \"85\", \"technology\", \"1999\", \"parts\", \"pm\", \"direct\",\n",
    "    \"cs\", \"meeting\", \"original\", \"project\", \"re\", \"edu\", \"table\",\n",
    "    \"conference\",\n",
    "]\n",
    "\n",
    "SPAMBASE_CHARS = [';', '(', '[', '!', '$', '#']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cac013-a8bb-4dfe-94c9-5ab581ceaf71",
   "metadata": {},
   "source": [
    "# Exercise 3 & Programming Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2270d1d9-7b17-41d2-a8c1-32a0af6e9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71706d4-1942-4c9e-97d4-7151e9dff439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word features: 48\n",
      "Keywords:\n",
      "['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet', 'order', 'mail', 'receive', 'will', 'people', 'report', 'addresses', 'free', 'business', 'email', 'you', 'credit', 'your', 'font', '000', 'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857', 'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct', 'cs', 'meeting', 'original', 'project', 're', 'edu', 'table', 'conference']\n",
      "Character features: ['char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#']\n",
      "Capital run features: ['capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total']\n"
     ]
    }
   ],
   "source": [
    "# All feature names\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "# Word-based features\n",
    "word_features = [f for f in feature_names if f.startswith(\"word_freq_\")]\n",
    "# Strip the prefix to get just the word\n",
    "keywords = [f.replace(\"word_freq_\", \"\") for f in word_features]\n",
    "\n",
    "print(\"Number of word features:\", len(word_features))\n",
    "print(\"Keywords:\")\n",
    "print(keywords)\n",
    "\n",
    "# Character-based features\n",
    "char_features = [f for f in feature_names if f.startswith(\"char_freq_\")]\n",
    "print(\"Character features:\", char_features)\n",
    "\n",
    "# Capital-run features\n",
    "capital_features = [f for f in feature_names if f.startswith(\"capital_run_length_\")]\n",
    "print(\"Capital run features:\", capital_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb4e2e5-132c-4f39-bf5a-e4aea12f824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9328804347826087\n",
      "Test accuracy:     0.9272529858849077\n",
      "\n",
      "File: Mails/test_mail01.txt\n",
      "Predicted label: NOT SPAM\n",
      "P(spam) = Hmmmmm 0.175\n",
      "\n",
      "File: Mails/test_mail02.txt\n",
      "Predicted label: NOT SPAM\n",
      "P(spam) = Hmmmmm 0.251\n",
      "\n",
      "File: Mails/test_mail03.txt\n",
      "Predicted label: SPAM\n",
      "P(spam) = Hmmmmm 0.608\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1) Load Spambase from UCI repository\n",
    "# ---------------------------------------------------------\n",
    "spambase = fetch_ucirepo(id=94)  # Spambase dataset\n",
    "\n",
    "X_full = spambase.data.features.copy()      # 57 input features\n",
    "y = spambase.data.targets.iloc[:, 0]       # target column (0 = ham, 1 = spam)\n",
    "\n",
    "# Get feature groups directly from the column names\n",
    "WORD_COLS = [c for c in X_full.columns if c.startswith(\"word_freq_\")]\n",
    "CHAR_COLS = [c for c in X_full.columns if c.startswith(\"char_freq_\")]\n",
    "CAPITAL_COLS = [c for c in X_full.columns if c.startswith(\"capital_run_length_\")]\n",
    "\n",
    "# We'll keep this canonical column order\n",
    "FEATURE_COLS = list(X_full.columns)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) Feature extraction from raw email text\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "WORD_RE = re.compile(r\"[A-Za-z0-9]+\")\n",
    "CAPITAL_RUN_RE = re.compile(r\"[A-Z]+\")\n",
    "\n",
    "\n",
    "def extract_features_from_text(text: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute the 57 Spambase features from raw email text.\n",
    "    Returns a pandas Series with index = FEATURE_COLS.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- word frequencies -----\n",
    "    tokens = [m.group(0).lower() for m in WORD_RE.finditer(text)]\n",
    "    total_words = len(tokens)\n",
    "    word_counts = {}\n",
    "\n",
    "    for col in WORD_COLS:\n",
    "        word = col.replace(\"word_freq_\", \"\")\n",
    "        word_counts[word] = 0\n",
    "\n",
    "    for t in tokens:\n",
    "        if t in word_counts:\n",
    "            word_counts[t] += 1\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    for col in WORD_COLS:\n",
    "        word = col.replace(\"word_freq_\", \"\")\n",
    "        count = word_counts[word]\n",
    "        freq = 100.0 * count / total_words if total_words > 0 else 0.0\n",
    "        features[col] = freq\n",
    "\n",
    "    # ----- character frequencies -----\n",
    "    total_chars = len(text)\n",
    "    for col in CHAR_COLS:\n",
    "        ch = col.replace(\"char_freq_\", \"\")\n",
    "        count_ch = text.count(ch)\n",
    "        freq_ch = 100.0 * count_ch / total_chars if total_chars > 0 else 0.0\n",
    "        features[col] = freq_ch\n",
    "\n",
    "    # ----- capital run length features -----\n",
    "    runs = [len(m.group(0)) for m in CAPITAL_RUN_RE.finditer(text)]\n",
    "    if runs:\n",
    "        total_cap = sum(runs)\n",
    "        longest = max(runs)\n",
    "        avg = total_cap / len(runs)\n",
    "    else:\n",
    "        total_cap = 0\n",
    "        longest = 0\n",
    "        avg = 0.0\n",
    "\n",
    "    features[\"capital_run_length_average\"] = avg\n",
    "    features[\"capital_run_length_longest\"] = longest\n",
    "    features[\"capital_run_length_total\"] = total_cap\n",
    "\n",
    "    # Return as Series in canonical column order\n",
    "    return pd.Series(features)[FEATURE_COLS]\n",
    "\n",
    "\n",
    "def extract_features_from_file(path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"Read a text file and return a 1×57 DataFrame of features.\"\"\"\n",
    "    text = Path(path).read_text(encoding=\"latin1\", errors=\"ignore\")\n",
    "    s = extract_features_from_text(text)\n",
    "    return s.to_frame().T   # shape (1, 57)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Train a simple spam classifier on Spambase\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full[FEATURE_COLS].values, y.values, test_size=0.2, random_state=42, stratify=y.values)\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", clf.score(X_train, y_train))\n",
    "print(\"Test accuracy:    \", clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) Apply to three example emails\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "example_files = [\"Mails/test_mail01.txt\", \"Mails/test_mail02.txt\", \"Mails/test_mail03.txt\"]  # adjust names/paths\n",
    "\n",
    "for fname in example_files:\n",
    "    if not Path(fname).exists():\n",
    "        print(f\"\\nFile {fname} not found – skip.\")\n",
    "        continue\n",
    "\n",
    "    X_new = extract_features_from_file(fname)[FEATURE_COLS].values\n",
    "    pred = clf.predict(X_new)[0]\n",
    "    proba = clf.predict_proba(X_new)[0, 1]\n",
    "\n",
    "    label = \"SPAM\" if pred == 1 else \"NOT SPAM\"\n",
    "    print(f\"\\nFile: {fname}\")\n",
    "    print(f\"Predicted label: {label}\")\n",
    "    print(f\"P(spam) = Hmmmmm {proba:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce0aa0-b3a8-414c-8755-6e583a505488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
